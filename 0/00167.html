<!DOCTYPE html><html><head><meta charset=utf-8 /><meta name=viewport content="width=device-width, initial-scale=1" /><link href=https://indrecap.com/.resource/site.css rel=stylesheet /></head><body><header></header><main><div class=container><div id=article><h1>Microsoft urges governments to act faster on AI regulation</h1><p><img src=https://a1.indrecap.com/0/00167.webp height=281 class=antiCLS /></p><p class=imgCredit>Tara Winstead/pexels</p><p>The tech giant's president warns of the risks and opportunities of artificial intelligence and calls for a global initiative to ensure its safe and ethical use.</p><h2>AI is ubiquitous and powerful, but needs oversight</h2><p>Artificial intelligence (AI) is a technology that has more potential for the good of humanity than any other invention preceding it, according to Brad Smith, Microsoft's president and vice chair. He said AI is already used in various fields such as medicine, disaster relief, and entertainment, but also poses challenges such as job disruption, misinformation, and discrimination.</p><p>Smith made these remarks on CBS' "Face the Nation" on Sunday, where he advocated for faster and more comprehensive regulation of AI by governments around the world. He said companies need to step up and be responsible for their AI products, but they also need clear and consistent rules from authorities to ensure the technology is developed and deployed safely and ethically.</p><h2>Microsoft proposes specific measures for AI regulation</h2><p>Smith outlined some of the measures that Microsoft believes are necessary for effective AI regulation. These include:</p><ul><li>Designating certain AI systems used in critical infrastructure as "high risk" and requiring them to have a safety break that can fully turn them off or slow them down in case of malfunction or emergency.</li><li>Clarifying when additional legal obligations apply to an AI system, such as liability, transparency, and accountability.</li><li>Labeling AI-generated content such as images or videos to make it clear that they are not real and prevent deception or manipulation.</li><li>Creating a watermark system that can embed metadata into AI-generated content and detect when it is altered or removed.</li><li>Establishing a new government agency to regulate AI systems that are more powerful than GPT4, which can generate realistic text and images on its own. Smith said such systems should be developed and deployed only in licensed AI data centers that can protect them from cybersecurity, physical security, and national security threats.</li><li>Launching a global initiative that brings together the tech sector and governments to set common standards and norms for AI use, especially in the context of an upcoming US presidential election and the ongoing threat of foreign cyber influence operations.</li></ul><h2>Microsoft's role and vision in the AI field</h2><p>Microsoft is one of the leading companies in the AI field, with a vision to empower every person and organization on the planet to achieve more with AI. The company has invested heavily in AI research and development, as well as in partnerships with other organizations such as OpenAI, which makes ChatGPT.</p><p>Microsoft has also pledged to build AI into many of its products, such as Windows, Office, Azure, Bing, Xbox, LinkedIn, and HoloLens. The company has also launched several initiatives to promote ethical and responsible AI practices, such as its AI for Good program, its Responsible AI Champs network, and its Aether Committee.</p><p>Smith said Microsoft is committed to creating trustworthy AI that respects human values and rights. He said the company welcomes constructive dialogue and collaboration with governments, regulators, civil society, academia, and other stakeholders to ensure that AI serves the common good.</p><h6>Microsoft, artificial intelligence, regulation, Brad Smith</h6></div></div></main><footer></footer><script src=https://indrecap.com/.resource/site.js></script></body></html>